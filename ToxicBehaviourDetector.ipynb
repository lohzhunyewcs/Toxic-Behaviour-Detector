{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ToxicBehaviourDetector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPYFl4L8pl5D",
        "colab_type": "text"
      },
      "source": [
        "# TODO:\n",
        "\n",
        "\n",
        "1.   Finish DataLoaders so you don't have to do manual batch and/or SGD\n",
        "2.   Try other models like attention models etc.\n",
        "3.   Use BERT or other SOTA models\n",
        "4.   Reprocess Dataset uinsg torchtext\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dvERk0hieO0",
        "colab_type": "text"
      },
      "source": [
        "Download Existing Repo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5_MNktGonIO",
        "colab_type": "code",
        "outputId": "5a0eceaf-1591-41b2-ea5b-b3e6c0cb6ca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "source": [
        "!wget https://github.com/lohzhunyewcs/Toxic-Behaviour-Detector/archive/master.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-06 12:51:33--  https://github.com/lohzhunyewcs/Toxic-Behaviour-Detector/archive/master.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/lohzhunyewcs/Toxic-Behaviour-Detector/zip/master [following]\n",
            "--2020-04-06 12:51:34--  https://codeload.github.com/lohzhunyewcs/Toxic-Behaviour-Detector/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [ <=>                ]   7.00K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-04-06 12:51:35 (11.9 MB/s) - ‘master.zip’ saved [7167]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL9Hq0dvwR-7",
        "colab_type": "code",
        "outputId": "d628b2d7-b577-433e-f393-e7205d08febc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "master.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOrnNSQzwg_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q master.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXKD5ED3hXgM",
        "colab_type": "code",
        "outputId": "fc9e53ac-2d7e-4f27-a715-691b3f49b246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "print(os.listdir())\n",
        "os.rename('Toxic-Behaviour-Detector-master', 'src')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'master.zip', 'Toxic-Behaviour-Detector-master', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFm-y4Lxibmm",
        "colab_type": "text"
      },
      "source": [
        "Downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlh-_Z-kjUeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('src/labeled_data', exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUUEd2GqjCY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    def get_confirm_token(response):\n",
        "        for key, value in response.cookies.items():\n",
        "            if key.startswith('download_warning'):\n",
        "                return value\n",
        "\n",
        "        return None\n",
        "\n",
        "    def save_response_content(response, destination):\n",
        "        CHUNK_SIZE = 32768\n",
        "\n",
        "        with open(destination, \"wb\") as f:\n",
        "            for chunk in response.iter_content(CHUNK_SIZE):\n",
        "                if chunk: # filter out keep-alive new chunks\n",
        "                    f.write(chunk)\n",
        "\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # TAKE ID FROM SHAREABLE LINK\n",
        "    file_id = '1rqC8VZskMf1Shgo6ejTu5nnbZn4K5ngT'\n",
        "    # DESTINATION FILE ON YOUR DISK\n",
        "    destination = 'src/labeled_data/labeled_data.csv'\n",
        "    download_file_from_google_drive(file_id, destination)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOKJdk0Mg6cq",
        "colab_type": "text"
      },
      "source": [
        "We'll be using 3 Libraries to train\n",
        "1.   TensorFlow\n",
        "2.   PyTorch\n",
        "3.   PyTorch-Lightning(for their seamless TPU support)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAOhYy_HhEcp",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqUZD8S-hFoK",
        "colab_type": "text"
      },
      "source": [
        "PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2vQ08D1jzAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "from torch.utils.data.dataset import random_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNGu_mSekRoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DotaChatDataset(Dataset):\n",
        "  def __init__(self, file_name):\n",
        "    self.chats = []\n",
        "    self.is_toxics = []\n",
        "    index_counter = 0\n",
        "    self.word_to_idx = {}\n",
        "    self.max_length = 0\n",
        "    with open(f'src/labeled_data/{file_name}', 'r') as file:\n",
        "      for index, line in enumerate(file):\n",
        "        if index == 0:\n",
        "          continue\n",
        "        line = line.strip().split(',')\n",
        "        chat, is_toxic = line\n",
        "        self.chats.append(chat)\n",
        "        self.is_toxics.append(int(is_toxic))\n",
        "\n",
        "        splitted_chat = chat.split(' ')\n",
        "        self.max_length = max(self.max_length, len(splitted_chat))\n",
        "        for word in splitted_chat:\n",
        "          if word not in self.word_to_idx:\n",
        "            self.word_to_idx[word] = index_counter\n",
        "            index_counter += 1\n",
        "    self.offsets = [0] + [len(i) for i in self.chats]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.chats)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x = [self.word_to_idx[i] for i in self.chats[idx].split(' ')]\n",
        "    x = torch.tensor(x)\n",
        "    # x = torch.cat(x)\n",
        "    return {\n",
        "        'x': x.float(),\n",
        "        'y': torch.tensor([self.is_toxics[idx]]).float()\n",
        "    }\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2nkO1wCl-qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chat_dataset = DotaChatDataset('labeled_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-P6Wm0aqPwq",
        "colab_type": "code",
        "outputId": "b5b9f05c-d491-4d11-e2d6-2ef5c37c8b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(len(chat_dataset.word_to_idx))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfh56ZXimInG",
        "colab_type": "code",
        "outputId": "b1fb8f58-f055-4f50-c3f8-424fe2630986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Test if dataset works\n",
        "for i in range(5): \n",
        "  print(chat_dataset[i])\n",
        "  a = chat_dataset[i]\n",
        "  print(type(a['y']))\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'x': tensor([0.]), 'y': tensor([0.])}\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSvtQHvtpfai",
        "colab_type": "text"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLqPnB4Tpd07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsToxic(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n",
        "        super().__init__()\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
        "\n",
        "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
        "\n",
        "        self.hidden_cell = None\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
        "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
        "        return torch.sigmoid(predictions[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHBNSzgb0tRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = len(chat_dataset.word_to_idx)\n",
        "EMBED_DIM = 32\n",
        "NUM_CLASS = 1\n",
        "model = IsToxic()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyDHF22StRXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rb7Q4Ett-Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_round(item):\n",
        "  if item >= 0.5:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# Training Function\n",
        "def train(train_dataset):\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  \n",
        "  for index, data in enumerate(train_dataset):\n",
        "    optimizer.zero_grad()\n",
        "    model.hidden_cell = None\n",
        "    x = data['x'].to(device)\n",
        "    y = data['y'].to(device)\n",
        "    output = model(x)\n",
        "    # print(f'x: {x} output: {output}, y: {y}')\n",
        "    loss = criterion(output, y)\n",
        "    train_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # print(f'output: {output}')\n",
        "    train_acc += int(my_round(output.item()) == y)\n",
        "  \n",
        "  return train_loss/(index + 1), train_acc/(index + 1)\n",
        "\n",
        "# validation Function\n",
        "def valid(val_dataset):\n",
        "  valid_loss = 0\n",
        "  valid_acc = 0\n",
        "  \n",
        "  for index, data in enumerate(val_dataset):\n",
        "    x = data['x'].to(device)\n",
        "    y = data['y'].to(device)\n",
        "    with torch.no_grad():\n",
        "      output = model(x)\n",
        "      loss = criterion(output, y)\n",
        "      valid_loss += loss.item()\n",
        "      valid_acc += int(my_round(output.item()) == y)\n",
        "  \n",
        "  return valid_loss/(index + 1), valid_acc/(index + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3zp-kO2tPpb",
        "colab_type": "code",
        "outputId": "5c16a092-02e0-4bf7-a5d0-2491386b649a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "\n",
        "model = model.to(device)\n",
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=4.00)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "EPOCHS = 5\n",
        "\n",
        "train_size = int(len(chat_dataset) * 0.95)\n",
        "train_dataset, val_dataset = random_split(chat_dataset, [train_size, len(chat_dataset) - train_size])\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_dataset)\n",
        "  valid_loss, valid_acc = valid(val_dataset)\n",
        "\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs / 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "  print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 17 minutes, 26 seconds\n",
            "\tLoss: 15.4012(train)\t|\tAcc: 47.5%(train)\n",
            "\tLoss: 14.8848(valid)\t|\tAcc: 46.1%(valid)\n",
            "Epoch: 2  | time in 17 minutes, 33 seconds\n",
            "\tLoss: 14.7898(train)\t|\tAcc: 46.5%(train)\n",
            "\tLoss: 14.8844(valid)\t|\tAcc: 46.1%(valid)\n",
            "Epoch: 3  | time in 17 minutes, 32 seconds\n",
            "\tLoss: 14.7898(train)\t|\tAcc: 46.5%(train)\n",
            "\tLoss: 14.8844(valid)\t|\tAcc: 46.1%(valid)\n",
            "Epoch: 4  | time in 17 minutes, 36 seconds\n",
            "\tLoss: 14.7898(train)\t|\tAcc: 46.5%(train)\n",
            "\tLoss: 14.8844(valid)\t|\tAcc: 46.1%(valid)\n",
            "Epoch: 5  | time in 17 minutes, 41 seconds\n",
            "\tLoss: 14.7898(train)\t|\tAcc: 46.5%(train)\n",
            "\tLoss: 14.8844(valid)\t|\tAcc: 46.1%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u3IjTZwhCRt",
        "colab_type": "text"
      },
      "source": [
        "PyTorchLighNing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1JmpklbgsVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch-lightning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOE3SwPQwpFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pytorch_lightning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC_SDqi6gmfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}